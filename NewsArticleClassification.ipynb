{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading pretrained word2vec model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NewsCategoryData.json', 'r') as f:\n",
    "    news_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'short_description': 'She left her husband. He killed their children. Just another day in America.',\n",
       " 'headline': 'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV',\n",
       " 'date': '2018-05-26',\n",
       " 'link': 'https://www.huffingtonpost.com/entry/texas-amanda-painter-mass-shooting_us_5b081ab4e4b0802d69caad89',\n",
       " 'authors': 'Melissa Jeltsen',\n",
       " 'category': 'CRIME'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['articles'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a list of strings containing short descrption and headline and preprocessing them. \n",
    "news_description_list = []\n",
    "for news in news_data['articles']:\n",
    "    str_to_append = news['short_description'] + news['headline']\n",
    "    str_to_append = re.sub(r\"\\W\",\" \",str_to_append)\n",
    "    str_to_append = re.sub(r\"\\.\",\" \",str_to_append)\n",
    "    str_to_append = re.sub(r\"\\s+[a-z0-9]\\s+\",\" \",str_to_append)\n",
    "    str_to_append = re.sub(r\"\\s+\",\" \",str_to_append)\n",
    "    str_to_append = str_to_append.lower()\n",
    "    news_description_list.append(str_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "21.0\n",
      "22.0\n",
      "23.0\n",
      "24.0\n",
      "25.0\n",
      "26.0\n",
      "27.0\n",
      "28.0\n",
      "29.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "33.0\n",
      "34.0\n",
      "35.0\n",
      "36.0\n",
      "37.0\n",
      "38.0\n",
      "39.0\n",
      "40.0\n",
      "41.0\n",
      "42.0\n",
      "43.0\n",
      "44.0\n",
      "45.0\n",
      "46.0\n",
      "47.0\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "51.0\n",
      "52.0\n",
      "53.0\n",
      "54.0\n",
      "55.0\n",
      "56.0\n",
      "57.0\n",
      "58.0\n",
      "59.0\n",
      "60.0\n",
      "61.0\n",
      "62.0\n",
      "63.0\n",
      "64.0\n",
      "65.0\n",
      "66.0\n",
      "67.0\n",
      "68.0\n",
      "69.0\n",
      "70.0\n",
      "71.0\n",
      "72.0\n",
      "73.0\n",
      "74.0\n",
      "75.0\n",
      "76.0\n",
      "77.0\n",
      "78.0\n",
      "79.0\n",
      "80.0\n",
      "81.0\n",
      "82.0\n",
      "83.0\n",
      "84.0\n",
      "85.0\n",
      "86.0\n",
      "87.0\n",
      "88.0\n",
      "89.0\n",
      "90.0\n",
      "91.0\n",
      "92.0\n",
      "93.0\n",
      "94.0\n",
      "95.0\n",
      "96.0\n",
      "97.0\n",
      "98.0\n",
      "99.0\n",
      "100.0\n",
      "101.0\n",
      "102.0\n",
      "103.0\n",
      "104.0\n",
      "105.0\n",
      "106.0\n",
      "107.0\n",
      "108.0\n",
      "109.0\n",
      "110.0\n",
      "111.0\n",
      "112.0\n",
      "113.0\n",
      "114.0\n",
      "115.0\n",
      "116.0\n",
      "117.0\n",
      "118.0\n",
      "119.0\n",
      "120.0\n",
      "121.0\n",
      "122.0\n",
      "123.0\n",
      "124.0\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords\n",
    "filtered_news_list = []\n",
    "i=0\n",
    "for news in news_description_list:\n",
    "    sentence = []\n",
    "    words = nltk.word_tokenize(news)\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            sentence.append(word)\n",
    "    if i%1000 == 0: \n",
    "        print(i/1000)\n",
    "    filtered_news_list.append(sentence)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "19.0\n",
      "20.0\n",
      "21.0\n",
      "22.0\n",
      "23.0\n",
      "24.0\n",
      "25.0\n",
      "26.0\n",
      "27.0\n",
      "28.0\n",
      "29.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "33.0\n",
      "34.0\n",
      "35.0\n",
      "36.0\n",
      "37.0\n",
      "38.0\n",
      "39.0\n",
      "40.0\n",
      "41.0\n",
      "42.0\n",
      "43.0\n",
      "44.0\n",
      "45.0\n",
      "46.0\n",
      "47.0\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "51.0\n",
      "52.0\n",
      "53.0\n",
      "54.0\n",
      "55.0\n",
      "56.0\n",
      "57.0\n",
      "58.0\n",
      "59.0\n",
      "60.0\n",
      "61.0\n",
      "62.0\n",
      "63.0\n",
      "64.0\n",
      "65.0\n",
      "66.0\n",
      "67.0\n",
      "68.0\n",
      "69.0\n",
      "70.0\n",
      "71.0\n",
      "72.0\n",
      "73.0\n",
      "74.0\n",
      "75.0\n",
      "76.0\n",
      "77.0\n",
      "78.0\n",
      "79.0\n",
      "80.0\n",
      "81.0\n",
      "82.0\n",
      "83.0\n",
      "84.0\n",
      "85.0\n",
      "86.0\n",
      "87.0\n",
      "88.0\n",
      "89.0\n",
      "90.0\n",
      "91.0\n",
      "92.0\n",
      "93.0\n",
      "94.0\n",
      "95.0\n",
      "96.0\n",
      "97.0\n",
      "98.0\n",
      "99.0\n",
      "100.0\n",
      "101.0\n",
      "102.0\n",
      "103.0\n",
      "104.0\n",
      "105.0\n",
      "106.0\n",
      "107.0\n",
      "108.0\n",
      "109.0\n",
      "110.0\n",
      "111.0\n",
      "112.0\n",
      "113.0\n",
      "114.0\n",
      "115.0\n",
      "116.0\n",
      "117.0\n",
      "118.0\n",
      "119.0\n",
      "120.0\n",
      "121.0\n",
      "122.0\n",
      "123.0\n",
      "124.0\n"
     ]
    }
   ],
   "source": [
    "lmz_news_list = []\n",
    "for news in filtered_news_list:\n",
    "    sentence = []\n",
    "    for word in news:\n",
    "        new_word = lemmatizer.lemmatize(word)\n",
    "        sentence.append(new_word)\n",
    "    lmz_news_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz = Tokenizer(num_words=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz.fit_on_texts(lmz_news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz_sequences = tkz.texts_to_sequences(lmz_news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pad_sequences(tkz_sequences,maxlen=40,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tkz.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67585"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 516,   61,  127,  323,   63,   33, 3890, 3789,   13, 4403,    2,\n",
       "        234, 1376, 1674, 2899, 8415,  164, 1163,   76,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[23484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the embedding matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word,i in word_index.items():\n",
    "    if word in model.vocab:\n",
    "        vec = model[word]\n",
    "        embedding_matrix[i] = vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Labels\n",
    "labels = []\n",
    "for news in news_data['articles']:\n",
    "    labels.append(news['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'category' : labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_labels = pd.get_dummies(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_ARTS</th>\n",
       "      <th>category_ARTS &amp; CULTURE</th>\n",
       "      <th>category_BLACK VOICES</th>\n",
       "      <th>category_BUSINESS</th>\n",
       "      <th>category_COLLEGE</th>\n",
       "      <th>category_COMEDY</th>\n",
       "      <th>category_CRIME</th>\n",
       "      <th>category_EDUCATION</th>\n",
       "      <th>category_ENTERTAINMENT</th>\n",
       "      <th>category_FIFTY</th>\n",
       "      <th>...</th>\n",
       "      <th>category_SPORTS</th>\n",
       "      <th>category_STYLE</th>\n",
       "      <th>category_TASTE</th>\n",
       "      <th>category_TECH</th>\n",
       "      <th>category_THE WORLDPOST</th>\n",
       "      <th>category_TRAVEL</th>\n",
       "      <th>category_WEIRD NEWS</th>\n",
       "      <th>category_WOMEN</th>\n",
       "      <th>category_WORLD NEWS</th>\n",
       "      <th>category_WORLDPOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_ARTS  category_ARTS & CULTURE  category_BLACK VOICES  \\\n",
       "0              0                        0                      0   \n",
       "1              0                        0                      0   \n",
       "2              0                        0                      0   \n",
       "3              0                        0                      0   \n",
       "4              0                        0                      0   \n",
       "\n",
       "   category_BUSINESS  category_COLLEGE  category_COMEDY  category_CRIME  \\\n",
       "0                  0                 0                0               1   \n",
       "1                  0                 0                0               0   \n",
       "2                  0                 0                0               0   \n",
       "3                  0                 0                0               0   \n",
       "4                  0                 0                0               0   \n",
       "\n",
       "   category_EDUCATION  category_ENTERTAINMENT  category_FIFTY  \\\n",
       "0                   0                       0               0   \n",
       "1                   0                       1               0   \n",
       "2                   0                       1               0   \n",
       "3                   0                       1               0   \n",
       "4                   0                       1               0   \n",
       "\n",
       "          ...          category_SPORTS  category_STYLE  category_TASTE  \\\n",
       "0         ...                        0               0               0   \n",
       "1         ...                        0               0               0   \n",
       "2         ...                        0               0               0   \n",
       "3         ...                        0               0               0   \n",
       "4         ...                        0               0               0   \n",
       "\n",
       "   category_TECH  category_THE WORLDPOST  category_TRAVEL  \\\n",
       "0              0                       0                0   \n",
       "1              0                       0                0   \n",
       "2              0                       0                0   \n",
       "3              0                       0                0   \n",
       "4              0                       0                0   \n",
       "\n",
       "   category_WEIRD NEWS  category_WOMEN  category_WORLD NEWS  \\\n",
       "0                    0               0                    0   \n",
       "1                    0               0                    0   \n",
       "2                    0               0                    0   \n",
       "3                    0               0                    0   \n",
       "4                    0               0                    0   \n",
       "\n",
       "   category_WORLDPOST  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_labels = enc_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding,Dense,Conv1D,MaxPooling1D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(67585 + 1,300,weights=[embedding_matrix],input_length=40,trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(256,3,activation='relu',padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling1D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(128,3,activation='relu',padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling1D(pool_size=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256,activation='relu',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(31,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 40, 300)           20275800  \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 40, 256)           230656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 20, 128)           98432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               164096    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 31)                7967      \n",
      "=================================================================\n",
      "Total params: 20,776,951\n",
      "Trainable params: 501,151\n",
      "Non-trainable params: 20,275,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, enc_labels, test_size=0.3, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87492 samples, validate on 37497 samples\n",
      "Epoch 1/3\n",
      "87492/87492 [==============================] - 59s 672us/step - loss: 1.7206 - acc: 0.5223 - val_loss: 1.4541 - val_acc: 0.5813\n",
      "Epoch 2/3\n",
      "87492/87492 [==============================] - 57s 657us/step - loss: 1.2978 - acc: 0.6213 - val_loss: 1.3996 - val_acc: 0.5977\n",
      "Epoch 3/3\n",
      "87492/87492 [==============================] - 57s 656us/step - loss: 1.0864 - acc: 0.6731 - val_loss: 1.4002 - val_acc: 0.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64b5267438>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=3, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
